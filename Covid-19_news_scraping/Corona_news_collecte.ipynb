{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full. scraping import *\n",
    "import csv \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) snap Chromium/83.0.4103.106 Chrome/83.0.4103.106 Safari/537.36\"\n",
    "training_keywords = {'করোনা', 'কোভিড-১৯', 'উহান-ভাইরাস', 'নতুন ভ্যারিয়েন্টে করনা'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_csv(item):\n",
    "    with open('data.csv', 'a+', newline='') as file:\n",
    "        file_header = ['Tittle', 'link']\n",
    "        writer = csv.writer(file, file_header)\n",
    "        writer.writerow(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_date_time(string):\n",
    "    items = string.find_all('time')\n",
    "    if len(items)>0:\n",
    "        for i in items:\n",
    "            return i.get_text().strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_only_corona_news(links):\n",
    "    news_count = 0\n",
    "    for link in links:\n",
    "        news_link = get_valid_link(str(link.get('href')))\n",
    "        title = link.get_text().strip()\n",
    "        if news_link is None or len(title) <=0:\n",
    "            continue\n",
    "        title_words = set(title.split())\n",
    "        \n",
    "        if training_keywords.intersection(title_words):\n",
    "            store_in_csv([title, news_link])\n",
    "            news_count +=1\n",
    "        else:\n",
    "            metadata = scrap_url(news_link, headers).find_all('meta')\n",
    "            for tag in metadata:\n",
    "                if 'name' in tag.attrs.keys() and tag.attrs['name'].strip().lower() in ['keywords', 'description']:\n",
    "                    sample_keywords = set(tag.attrs['content'].strip().split())\n",
    "                    if training_keywords.intersection(sample_keywords):\n",
    "                        news_count +=1\n",
    "                        store_in_csv([title, news_link])\n",
    "                        \n",
    "    return news_count\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='bangla.bdnews24.com', port=443): Max retries exceeded with url: /media_bn/article1899981.bdnews?Mozilla/5.0%20(X11;%20Linux%20x86_64)%20AppleWebKit/537.36%20(KHTML,%20like%20Gecko)%20snap%20Chromium/83.0.4103.106%20Chrome/83.0.4103.106%20Safari/537.36 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fad4d455250>: Failed to establish a new connection: [Errno 110] Connection timed out'))\n",
      "Total 12 news collected\n",
      "Total time spent: 944.5629053115845 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    start_time = time.time()\n",
    "    total_news =0\n",
    "    with open('data.csv', 'w', newline='') as data:\n",
    "        writer = csv.DictWriter(data, fieldnames = ['Title', 'Link'])\n",
    "        writer.writeheader()\n",
    "        \n",
    "    website_list = [\"https://jamuna.tv\", \"https://bangla.bdnews24.com\", \"https://somoynews.tv\", \"https://prothomalo.com\"]  # add target website URL\n",
    "    for web_url in website_list:\n",
    "        soup = scrap_url(web_url, headers)\n",
    "        all_links = soup.find_all('a')\n",
    "        total_news +=print_only_corona_news(all_links)\n",
    "    print(f'Total {total_news} news collected')\n",
    "    print(f'Total time spent: {time.time() - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>পটুয়াখালীতে ১৫ হাজার মানুষ করোনা টিকার দ্বিতীয়...</td>\n",
       "      <td>https://jamuna.tv/news/220576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>করোনা সচেতনতায় গুগলের ডুডল</td>\n",
       "      <td>https://jamuna.tv/news/215580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>করোনা সচেতনতায় গুগলের ডুডল</td>\n",
       "      <td>https://jamuna.tv/news/217424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>যেসব কারণে করোনা থেকে সেরে ওঠে খিচুড়ি খাবেন</td>\n",
       "      <td>https://jamuna.tv/news/225078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>করোনা দুর্যোগ: ভারতীয় মিডিয়া বনাম বাংলাদেশি ...</td>\n",
       "      <td>https://jamuna.tv/news/217120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  পটুয়াখালীতে ১৫ হাজার মানুষ করোনা টিকার দ্বিতীয়...   \n",
       "1                         করোনা সচেতনতায় গুগলের ডুডল   \n",
       "2                         করোনা সচেতনতায় গুগলের ডুডল   \n",
       "3        যেসব কারণে করোনা থেকে সেরে ওঠে খিচুড়ি খাবেন   \n",
       "4  করোনা দুর্যোগ: ভারতীয় মিডিয়া বনাম বাংলাদেশি ...   \n",
       "\n",
       "                            Link  \n",
       "0  https://jamuna.tv/news/220576  \n",
       "1  https://jamuna.tv/news/215580  \n",
       "2  https://jamuna.tv/news/217424  \n",
       "3  https://jamuna.tv/news/225078  \n",
       "4  https://jamuna.tv/news/217120  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
